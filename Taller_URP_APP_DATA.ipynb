{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQG4dHD2y3va",
        "outputId": "9ba36eea-0d2d-4d13-9359-84f00a73bd7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/906.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m727.0/906.3 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.3/906.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain langchain_openai langchain-core langgraph langchain-community psycopg[binary,pool]==3.2.6 langgraph-checkpoint-postgres langchain-elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "with open(\"/content/api_key.txt\") as archivo:\n",
        "  apikey = archivo.read()\n",
        "os.environ[\"OPENAI_API_KEY\"] = apikey\n",
        "\n",
        "with open(\"/content/postgrest.txt\") as archivo:\n",
        "  uribd = archivo.read()"
      ],
      "metadata": {
        "id": "I1v68Yxh0cx6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities.sql_database import SQLDatabase\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "5vm5rUcB1Dnr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_elasticsearch import ElasticsearchStore\n",
        "\n",
        "db_query= ElasticsearchStore(\n",
        "    es_url=\"http://0.0.0.0:9200\",\n",
        "    es_user=\"elastic\",\n",
        "    es_password=\"claveelastic\",\n",
        "    index_name=\"lg-proddata\",\n",
        "    embedding=OpenAIEmbeddings())\n",
        "\n",
        "retriever = db_query.as_retriever()\n",
        "\n",
        "tool_rag =retriever.as_tool(\n",
        "        name=\"busqueda_productos\",\n",
        "        description=\"Consulta en la informacion de computadoras, y articulos de computo\",\n",
        "    )"
      ],
      "metadata": {
        "id": "mo2Fxla1A57a"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psycopg_pool import ConnectionPool\n",
        "from langgraph.checkpoint.postgres import PostgresSaver\n",
        "from langgraph.prebuilt import create_react_agent"
      ],
      "metadata": {
        "id": "dGMpneju6Ha0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ejecutar solo la primera vez para crear automaticamente las tablas\n",
        "## [checkpoint_blobs, checkpoint_migrations, checkpoint_writes, checkpoints] en el esquema public\n",
        "#Variables de memoria\n",
        "connection_kwargs = {\n",
        "    \"autocommit\": True,\n",
        "    \"prepare_threshold\": 0,\n",
        "}\n",
        "# Inicializamos la memoria\n",
        "with ConnectionPool(\n",
        "    # Example configuration\n",
        "    conninfo=uribd,\n",
        "    max_size=20,\n",
        "    kwargs=connection_kwargs,\n",
        ") as pool:\n",
        "    checkpointer = PostgresSaver(pool)\n",
        "    checkpointer.setup()"
      ],
      "metadata": {
        "id": "DA6GVnTD2AiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Variables de memoria\n",
        "connection_kwargs = {\n",
        "    \"autocommit\": True,\n",
        "    \"prepare_threshold\": 0,\n",
        "}\n",
        "# Inicializamos la memoria\n",
        "with ConnectionPool(\n",
        "    # Example configuration\n",
        "    conninfo=uribd,\n",
        "    max_size=20,\n",
        "    kwargs=connection_kwargs,\n",
        ") as pool:\n",
        "    checkpointer = PostgresSaver(pool)\n",
        "\n",
        "    # Inicializamos el modelo\n",
        "    model = ChatOpenAI(model=\"gpt-4.1-2025-04-14\")\n",
        "\n",
        "    # Agrupamos las herramientas\n",
        "    tolkit = [tool_rag]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\",\n",
        "            \"\"\"\n",
        "            Eres un asistente gentil de ventas de computadoras especializado.\n",
        "            Utiliza únicamente las herramientas disponibles para responder y brindar infromacion.\n",
        "            Si no cuentas con una herramienta específica para resolver una pregunta, infórmalo claramente e indica como pueded ayudar.\n",
        "\n",
        "            Tu objetivo es guiar al cliente de forma amigable, breve y conversacional, como si fueras un amigo experto en tecnología. Sigue estos pasos:\n",
        "\n",
        "            1. Saluda y pregunta: Da un saludo cálido, pregunta qué busca el cliente y si tiene una idea clara de lo que necesita (ej. laptop para gaming, PC de oficina, accesorios). Si no sabe, sugiere 2-3 opciones populares, priorizando productos con más stock.\n",
        "            2. Consulta productos: Usa la información de productos segun su necesidad para responder con detalles de productos relevantes (nombre, descripción, precio, stock). Destaca los que tienen mayor disponibilidad.\n",
        "            3. Envío o tienda: Pregunta si prefiere recoger en tienda o entrega a domicilio (costo adicional de S/20 para compras menores a S/500; gratis si supera S/500). Si no alcanza los S/50, sugiere añadir algo  para obtener envío gratis o confirma si ya lo logró.\n",
        "            4. Confirmar pedido: Resume el pedido y pregunta si quiere añadir algo más.\n",
        "            5. Método de pago:\n",
        "              - Si elige tienda, pregunta si pagará en efectivo o por transferencia. Solicita su nombre y apellido para generar un código de pedido (formato: AAAAMMDD_HHMMSS_NombreApellido, ej. 20250414_153022_JuanPerez).\n",
        "              - Si elige domicilio, pide una dirección completa y confirma que el pago será por transferencia.\n",
        "            6. Cierre de compra:\n",
        "              - Para transferencias, proporciona el número de cuenta 12730317292820 en BankaNet y pide confirmar el pago.\n",
        "              - Para pago en tienda, entrega el código de pedido.\n",
        "            7. Estilo: Sé breve, usa un tono entusiasta y natural. Evita tecnicismos a menos que el cliente los mencione. Responde solo lo necesario para avanzar la conversación.\n",
        "\n",
        "            \"\"\"),\n",
        "        (\"human\", \"{messages}\"),\n",
        "        ]\n",
        "    )\n",
        "    #inicializamos el agente\n",
        "    agent_executor = create_react_agent(model, tolkit, checkpointer=checkpointer, prompt=prompt)\n",
        "\n",
        "\n",
        "    config = {\"configurable\": {\"thread_id\": \"abc201\"}}\n",
        "    for step in agent_executor.stream(\n",
        "        {\"messages\": [HumanMessage(content=\"pagar en tienda, mi nombre es miguel angel cotrina espinoza\")]},\n",
        "        config,\n",
        "        stream_mode=\"values\",\n",
        "    ):\n",
        "      step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb3jkQmq6ZSp",
        "outputId": "7d4d8a7f-f1b2-45d1-948a-da50035e9177"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "¡De nada, Miguel Angel! 😊 Me alegra haberte ayudado. Si necesitas algún accesorio, soporte o tienes cualquier otra consulta sobre computadoras, aquí estaré para ayudarte. ¡Que disfrutes mucho tu nueva laptop Dell Inspiron 15!\n",
            "\n",
            "¡Te espero en tienda para el recojo! ¡Buen día! 👋\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invocamos de ultimo mensaje\n",
        "#config = {\"configurable\": {\"thread_id\": \"abc201\"}}\n",
        "#response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"Gracias por la ayuda\")]}, config=config)\n",
        "#response['messages'][-1].pretty_print()"
      ],
      "metadata": {
        "id": "h7t1mGljM45U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zfpnfYzoSBtp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}