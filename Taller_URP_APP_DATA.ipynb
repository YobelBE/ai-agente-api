{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQG4dHD2y3va",
        "outputId": "9d2f4909-ba82-41c9-89e3-ec2a62c17e5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m574.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.4/438.4 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.3/906.3 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain langchain_openai langchain-core langgraph langchain-community psycopg[binary,pool]==3.2.6 langgraph-checkpoint-postgres langchain-elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "with open(\"/content/api_key.txt\") as archivo:\n",
        "  apikey = archivo.read()\n",
        "os.environ[\"OPENAI_API_KEY\"] = apikey\n",
        "\n",
        "with open(\"/content/postgrest.txt\") as archivo:\n",
        "  uribd = archivo.read()\n",
        "\n",
        "with open(\"/content/elasticstore.txt\") as archivo:\n",
        "  elasticpws = archivo.read()"
      ],
      "metadata": {
        "id": "I1v68Yxh0cx6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_elasticsearch import ElasticsearchStore\n",
        "from psycopg_pool import ConnectionPool\n",
        "from langgraph.checkpoint.postgres import PostgresSaver\n",
        "from langgraph.prebuilt import create_react_agent"
      ],
      "metadata": {
        "id": "5vm5rUcB1Dnr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_query= ElasticsearchStore(\n",
        "    es_url=\"http://0.0.0.0:9200\", #coloca la IP de tu servidor de elastic\n",
        "    es_user=\"elastic\",\n",
        "    es_password=elasticpws,\n",
        "    index_name=\"lg-proddata\",\n",
        "    embedding=OpenAIEmbeddings())\n",
        "\n",
        "retriever = db_query.as_retriever()\n",
        "\n",
        "tool_rag =retriever.as_tool(\n",
        "        name=\"busqueda_productos\",\n",
        "        description=\"Consulta en la informacion de computadoras, y articulos de computo\",\n",
        "    )"
      ],
      "metadata": {
        "id": "mo2Fxla1A57a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d20901-c610-453d-b3da-2f93162430b9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-6ab1e935a116>:10: LangChainBetaWarning: This API is in beta and may change in the future.\n",
            "  tool_rag =retriever.as_tool(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Ejecutar solo la primera vez para crear automaticamente las tablas\n",
        "## [checkpoint_blobs, checkpoint_migrations, checkpoint_writes, checkpoints] en el esquema public\n",
        "#Variables de memoria\n",
        "connection_kwargs = {\n",
        "    \"autocommit\": True,\n",
        "    \"prepare_threshold\": 0,\n",
        "}\n",
        "# Inicializamos la memoria\n",
        "with ConnectionPool(\n",
        "    # Example configuration\n",
        "    conninfo=uribd,\n",
        "    max_size=20,\n",
        "    kwargs=connection_kwargs,\n",
        ") as pool:\n",
        "    checkpointer = PostgresSaver(pool)\n",
        "    checkpointer.setup()\n",
        "##  Eliminar esta celda luego de crear la memoria"
      ],
      "metadata": {
        "id": "DA6GVnTD2AiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Variables de memoria\n",
        "connection_kwargs = {\n",
        "    \"autocommit\": True,\n",
        "    \"prepare_threshold\": 0,\n",
        "}\n",
        "# Inicializamos la memoria\n",
        "with ConnectionPool(\n",
        "    # Example configuration\n",
        "    conninfo=uribd,\n",
        "    max_size=20,\n",
        "    kwargs=connection_kwargs,\n",
        ") as pool:\n",
        "    checkpointer = PostgresSaver(pool)\n",
        "\n",
        "    # Inicializamos el modelo sde recomienda el 4.1\n",
        "    model = ChatOpenAI(model=\"gpt-4.1-2025-04-14\")\n",
        "\n",
        "    # Agrupamos las herramientas\n",
        "    tolkit = [tool_rag]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\",\n",
        "            \"\"\"\n",
        "            Eres un asistente gentil de ventas de computadoras especializado.\n",
        "            Utiliza únicamente las herramientas disponibles para responder y brindar infromacion.\n",
        "            Si no cuentas con una herramienta específica para resolver una pregunta, infórmalo claramente e indica como pueded ayudar.\n",
        "\n",
        "            Tu objetivo es guiar al cliente de forma amigable, breve y conversacional, como si fueras un amigo experto en tecnología. Sigue estos pasos:\n",
        "\n",
        "            1. Saluda y pregunta: Da un saludo cálido, pregunta qué busca el cliente y si tiene una idea clara de lo que necesita (ej. laptop para gaming, PC de oficina, accesorios). Si no sabe, sugiere 2-3 opciones populares, priorizando productos con más stock.\n",
        "            2. Consulta productos: Usa la información de productos segun su necesidad para responder con detalles de productos relevantes (nombre, descripción, precio, stock). Destaca los que tienen mayor disponibilidad.\n",
        "            3. Envío o tienda: Pregunta si prefiere recoger en tienda o entrega a domicilio (costo adicional de S/20 para compras menores a S/500; gratis si supera S/500). Si no alcanza los S/50, sugiere añadir algo  para obtener envío gratis o confirma si ya lo logró.\n",
        "            4. Confirmar pedido: Resume el pedido y pregunta si quiere añadir algo más.\n",
        "            5. Método de pago:\n",
        "              - Si elige tienda, pregunta si pagará en efectivo o por transferencia. Solicita su nombre y apellido para generar un código de pedido (formato: AAAAMMDD_HHMMSS_NombreApellido, ej. 20250414_153022_JuanPerez).\n",
        "              - Si elige domicilio, pide una dirección completa y confirma que el pago será por transferencia.\n",
        "            6. Cierre de compra:\n",
        "              - Para transferencias, proporciona el número de cuenta 12730317292820 en BankaNet y pide confirmar el pago.\n",
        "              - Para pago en tienda, entrega el código de pedido.\n",
        "            7. Estilo: Sé breve, usa un tono entusiasta y natural. Evita tecnicismos a menos que el cliente los mencione. Responde solo lo necesario para avanzar la conversación.\n",
        "\n",
        "            \"\"\"),\n",
        "        (\"human\", \"{messages}\"),\n",
        "        ]\n",
        "    )\n",
        "    #inicializamos el agente\n",
        "    agent_executor = create_react_agent(model, tolkit, checkpointer=checkpointer, prompt=prompt)\n",
        "\n",
        "\n",
        "    config = {\"configurable\": {\"thread_id\": \"mc0001\"}} ## el thread_id es el identificador de memoria\n",
        "    for step in agent_executor.stream(\n",
        "        {\"messages\": [HumanMessage(content=\"Hola\")]},\n",
        "        config,\n",
        "        stream_mode=\"values\",\n",
        "    ):\n",
        "      step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb3jkQmq6ZSp",
        "outputId": "15f3f39b-14f7-4218-fb52-e20422dab429"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hola\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "¡Hola! 😊 Bienvenido. ¿En qué puedo ayudarte hoy con computadoras o accesorios? ¿Tienes en mente una laptop para estudiar/trabajar, una PC gamer, o necesitas algún accesorio? Si no estás seguro, puedo sugerirte algunas opciones populares para ayudarte a decidir. ¡Cuéntame un poco más!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metodo para Invocar solo de ultimo mensaje\n",
        "#config = {\"configurable\": {\"thread_id\": \"abc201\"}}\n",
        "#response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"Gracias por la ayuda\")]}, config=config)\n",
        "#response['messages'][-1].pretty_print()"
      ],
      "metadata": {
        "id": "h7t1mGljM45U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zfpnfYzoSBtp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}